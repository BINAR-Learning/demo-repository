
# 1. Product Requirements Document: AML News Analysis Web App


| **Field**      | **Value**                                      |
|:---------------|:-----------------------------------------------|
| Document Title | AML News Analysis Web App â€“ Product Requirements|
| Version        | 1.1                                            |
| Status         | Draft                                          |
| Author         | Gemini AI                                      |
| Date           | 29 July 2025                                   |


## 2. Introduction & Overview


### 2.1. Problem Statement
Financial crime compliance professionals, analysts, and researchers in Indonesia currently spend a significant amount of time manually searching various news websites to stay updated on money laundering, fraud, and other related illicit activities. This process is inefficient, prone to gaps, and makes it difficult to spot overarching trends.

### 2.2. Proposed Solution
This project is to develop a simple and effective web application that automates the collection, categorization, and analysis of financial crime-related news from key Indonesian sources. The application will provide a centralized dashboard to visualize trends and review relevant articles, saving users time and providing them with actionable insights.


## 3. Goals and Objectives


### 3.1. Automate Data Collection
Eliminate the need for manual searching by automatically scraping relevant news from a predefined list of sources.

### 3.2. Provide Centralized Insights
Offer a single dashboard where all relevant news is aggregated and organized.

### 3.3. Identify Key Trends
Enable users to easily visualize trends in financial crime reporting over time and across different categories.

### 3.4. Increase Efficiency
Significantly reduce the time required for market surveillance and research tasks.


## 4. Target Audience


### 4.1. Primary Users
- Compliance Analysts and AML Officers at financial institutions in Indonesia.

### 4.2. Secondary Users
- Financial crime researchers
- Investigative journalists
- Regulatory staff


## 5. Core Features & Requirements


### 5.1. News Scraping
The system must scrape news articles from a defined list of Indonesian news websites upon user request.

#### 5.1.1. Target Sources
The initial list of target websites will include:
- Detik.com
- Kompas.com
- Tempo.co
- CNNIndonesia.com
- CNBCIndonesia.com

#### 5.1.2. Search Keywords
The scraper will search for articles containing keywords such as: "pencucian uang" (money laundering), "korupsi", "penipuan" (fraud), "judi online" (online gambling), "suap" (bribery), "penggelapan pajak" (tax evasion).

#### 5.1.3. Data Extraction
For each relevant article, the system must extract:
- Article Title
- Full Article Text (for analysis)
- Publication Date
- Source URL
- Source Name (e.g., "Detik.com")

#### 5.1.4. Manual Data Refresh
The scraping process (defined in 5.1.1 to 5.1.3) will be initiated when the user clicks a dedicated "Refresh" button. The process must check the database to avoid adding duplicate articles based on the source URL.

### 5.2. AI-Powered Categorization
The system must use a Natural Language Processing (NLP) model to automatically categorize each new, unique article.

#### 5.2.1. Predefined Categories
The initial set of categories will be:
- Money Laundering
- Fraud
- Gambling
- Corruption
- Tax Evasion
- Other / Uncategorized

#### 5.2.2. Categorization Logic
The system will analyze the content of the article to assign it to the most relevant category before saving it to the database. An article can only belong to one primary category.

### 5.3. Data Persistence
The system must use a simple, file-based database to store and manage all scraped articles for historical analysis.

#### 5.3.1. Database Technology
The system will use **SQLite** as its database.

#### 5.3.2. Database Schema
A single table named `articles` will be used to store the data with the following structure:
- id (Primary Key, Integer)
- title (Text)
- url (Text, UNIQUE)
- source_name (Text)
- publication_date (Date/Timestamp)
- category (Text)
- full_text (Text)

#### 5.3.3. Data Retrieval
The web dashboard will query this database to populate all charts and tables.

### 5.4. Simple & Effective Web Dashboard
The web application will present the analyzed data from the SQLite database in a clean, simple, and effective dashboard.

#### 5.4.1. Date Filter
Users must be able to filter the entire dashboard by a date range (e.g., "Last 30 Days," "Last 6 Months," "Custom Range"). This will be handled by a WHERE clause in the SQL query.

#### 5.4.2. Trend Analysis Chart
The dashboard will display a line chart showing the number of relevant news articles published over time. This data will be generated by a GROUP BY query on the `publication_date`.

#### 5.4.3. Category Breakdown Chart
The dashboard will feature a bar chart showing the total count of articles for each category. This will be generated by a GROUP BY query on the `category` field.

#### 5.4.4. Recent Articles Table
The dashboard will display a simple, scrollable table of the most recent articles, retrieved with an ORDER BY `publication_date` DESC query. The table should show:
- Publication Date
- Article Title
- Source
- Assigned Category
- A clickable link to the original article.

#### 5.4.5. Data Refresh Button
The dashboard must include a clearly labeled button (e.g., "Refresh News Now") that triggers the data scraping and database update process.


## 6. Non-Functional Requirements


#### 6.1. Recommended Tech Stack
The application should be built using a simple, Python-based stack to facilitate rapid development.

##### 6.1.1. Web Framework
- Streamlit or Gradio

##### 6.1.2. Database
- SQLite

##### 6.1.3. Data Handling
- Pandas

##### 6.1.4. Web Scraping
- Requests & Beautiful Soup

##### 6.1.5. AI/NLP
- spaCy or Hugging Face Transformers

#### 6.2. Performance
The dashboard should load within 5 seconds for a typical query (e.g., 6 months of data).

#### 6.3. Simplicity
The user interface must be intuitive and require no training to use.


## 7. Out of Scope (Future Considerations)


The following features will not be included in Version 1.0 but may be considered for future releases:
* User accounts and login functionality.  
* Real-time push notifications or email alerts.  
* Advanced search and filtering within the article text.  
* Named Entity Recognition (NER) to extract names of people, organizations, and locations.  
* Support for international news sources.  
* A publicly accessible API.


## 8. Success Metrics

### 8.1. Primary Metric

- **Reduction in average time spent by a target user on manual news monitoring**  
  - **Target:** >50% reduction

### 8.2. Secondary Metrics

- **Number of relevant articles successfully scraped and categorized per week**
- **Positive qualitative feedback from a sample group of test users**
- **Dashboard load time remains under the defined performance target**